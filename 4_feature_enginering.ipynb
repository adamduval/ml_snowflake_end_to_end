{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.core.task import Task, StoredProcedureCall, Cron\n",
    "from snowflake.core.task.dagv1 import DAG, DAGTask, DAGOperation, CreateMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session connection\n",
    "session = Session.builder.configs(json.load(open(\"connection.json\"))).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(session: Session) -> str:\n",
    "    \"\"\"\n",
    "    Perform feature engineering on the modeled data by applying one-hot \n",
    "    encoding to categorical columns and creating separate tables for each \n",
    "    category.\n",
    "    \n",
    "    This function takes a session object connected to Snowflake and processes \n",
    "    a pre-modeled dataset from the 'data_model_one' table. The steps involved \n",
    "    are as follows:\n",
    "    \n",
    "    Args:\n",
    "        session (Session): An active Snowflake session object used for SQL \n",
    "                           operations.\n",
    "    \n",
    "    Returns:\n",
    "        str: A status message indicating the completion of the feature \n",
    "             engineering process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get modeled data\n",
    "    data_model_df = session.table('data_model_one')\n",
    "\n",
    "    # List of categorical columns\n",
    "    cat_cols = [\n",
    "        'site',\n",
    "        'storage',\n",
    "        'start_date',\n",
    "        'type',\n",
    "        'end_date'\n",
    "    ]\n",
    "\n",
    "    # Initialize the OneHotEncoder\n",
    "    ohe = OneHotEncoder(\n",
    "        input_cols=cat_cols,\n",
    "        output_cols=cat_cols,\n",
    "        drop_input_cols=True,\n",
    "        drop=\"first\",\n",
    "        handle_unknown=\"ignore\"\n",
    "    )\n",
    "\n",
    "    # Apply one-hot encoding\n",
    "    ohe_df = ohe.fit(data_model_df).transform(data_model_df)\n",
    "\n",
    "    # Create separate dataframes for each category by dropping irrelevant columns\n",
    "    category_1_ohe = ohe_df.drop(['category_2_pct', 'category_3_pct'])\n",
    "    category_2_ohe = ohe_df.drop(['category_1_pct', 'category_3_pct'])\n",
    "    category_3_ohe = ohe_df.drop(['category_1_pct', 'category_2_pct'])\n",
    "\n",
    "    # Save each category dataframe as a separate table in Snowflake\n",
    "    category_1_ohe.write.mode(\"overwrite\").save_as_table(\"category_1_feats\")\n",
    "    category_2_ohe.write.mode(\"overwrite\").save_as_table(\"category_2_feats\")\n",
    "    category_3_ohe.write.mode(\"overwrite\").save_as_table(\"category_3_feats\")\n",
    "\n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the feature_engineering function as a Snowflake stored procedure\n",
    "procedure = session.sproc.register(\n",
    "    func=feature_engineering,\n",
    "    name=\"feature_engineering\",\n",
    "    packages=[\n",
    "        'snowflake-snowpark-python',\n",
    "        'snowflake-ml-python'\n",
    "    ],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML\",\n",
    "    replace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature engineering task with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL to create the task\n",
    "create_task_sql = \"\"\"\n",
    "CREATE OR REPLACE TASK feature_engineering_task\n",
    "WAREHOUSE = ml_warehouse\n",
    "AFTER data_engineering_task\n",
    "COMMENT = 'Run feature engineering after data engineering'\n",
    "AS\n",
    "CALL feature_engineering();\n",
    "\"\"\"\n",
    "\n",
    "# SQL to enable the task\n",
    "enable_task_sql = \"ALTER TASK feature_engineering_task RESUME\"\n",
    "\n",
    "# Create the task\n",
    "with session.connection() as conn:\n",
    "    conn.cursor().execute(create_task_sql)\n",
    "\n",
    "# Enable the task\n",
    "with session.connection() as conn:\n",
    "    conn.cursor().execute(enable_task_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature engineering task with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the task object\n",
    "feature_engineering_task_py = Task(\n",
    "    definition=StoredProcedureCall(procedure),\n",
    "    name='data_engineering_task_py',\n",
    "    warehouse='fishtalk_ml_warehouse',\n",
    "    comment='Run of feature_engineering',\n",
    ")\n",
    "\n",
    "# Create the task\n",
    "root = Root(session)\n",
    "tasks = root.databases[\"data\"].schemas[\"ml\"].tasks\n",
    "tasks.create(feature_engineering_task_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create simple DAG to run feature engineering after data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = root.databases[\"data\"].schemas[\"ml\"]\n",
    "\n",
    "# Create DAG object\n",
    "dag = DAG(\n",
    "    name=\"ml_dag\",\n",
    "    schedule=Cron('0 0 * * *', 'UTC'),\n",
    ")\n",
    "\n",
    "# Create DAG tasks\n",
    "with dag:\n",
    "    data_eng_task = DAGTask(\n",
    "        name=\"Data Engineering\",\n",
    "        definition=StoredProcedureCall(\n",
    "            'data_engineering',\n",
    "            stage_location='@ML'\n",
    "        ),\n",
    "        warehouse=\"ML_WH\",\n",
    "    )\n",
    "    \n",
    "    feat_eng_task = DAGTask(\n",
    "        name=\"Feature Engineering\",\n",
    "        definition=StoredProcedureCall(procedure),\n",
    "        warehouse=\"ML_WH\",\n",
    "    )\n",
    "    \n",
    "    # Set task dependencies\n",
    "    data_eng_task >> feat_eng_task\n",
    "\n",
    "# Deploy DAG\n",
    "dag_op = DAGOperation(schema)\n",
    "dag_op.deploy(dag, mode=CreateMode.or_replace)\n",
    "\n",
    "# Enable DAG\n",
    "dag_op.run(dag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
