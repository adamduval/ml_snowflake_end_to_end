{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col as F_col, max as F_max\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.core.task import Task\n",
    "from snowflake.core.task import StoredProcedureCall\n",
    "from snowflake.core.task import Cron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session connection\n",
    "session = Session.builder.configs(json.load(open(\"connection.json\"))).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Data Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_engineering(session: Session) -> str:\n",
    "    \"\"\"\n",
    "    Perform data engineering tasks on raw data from Snowflake\n",
    "    and save the transformed data as a new table.\n",
    "\n",
    "    This function is designed to prepare data for further analysis or \n",
    "    modeling by transforming raw input into a structured format. It \n",
    "    ensures that all necessary preprocessing steps are completed, such \n",
    "    as handling missing values and normalizing category proportions. \n",
    "\n",
    "    Args:\n",
    "        session (Session): An active Snowflake session object\n",
    "                          used to run SQL operations.\n",
    "\n",
    "    Returns:\n",
    "        str: A status message indicating the completion of the\n",
    "             data engineering process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get raw data\n",
    "    raw_data_a = session.table(\"raw_data_a\")\n",
    "\n",
    "    # Select and aggregate\n",
    "    model_one_df = (\n",
    "        raw_data_a.select(\n",
    "            \"id\",\n",
    "            \"lot\",\n",
    "            \"site\",\n",
    "            \"storage\",\n",
    "            \"start_date\",\n",
    "            \"end_date\",\n",
    "            \"type\",\n",
    "            \"category_1\",\n",
    "            \"category_2\",\n",
    "            \"category_3\",\n",
    "        )\n",
    "        .filter(F_col(\"lot\").is_not_null())\n",
    "        .group_by(\n",
    "            \"id\",\n",
    "            \"site\",\n",
    "            \"storage\",\n",
    "            \"start_date\",\n",
    "            \"type\",\n",
    "            \"category_1\",\n",
    "            \"category_2\",\n",
    "            \"category_3\",\n",
    "        )\n",
    "        .agg(F_max(\"end_date\").alias(\"max_end_date\"))\n",
    "        .distinct()\n",
    "        .order_by(\"id\")\n",
    "    )\n",
    "\n",
    "    # Fill empty category measures\n",
    "    model_one_df = model_one_df.fillna(\n",
    "        0,\n",
    "        subset=[\"category_1\", \"category_2\", \"category_3\"]\n",
    "    )\n",
    "\n",
    "    # Add calculated total F_column\n",
    "    model_one_df = model_one_df.withF_column(\n",
    "        \"total\",\n",
    "        F_col(\"category_1\") + F_col(\"category_2\") + F_col(\"category_3\")\n",
    "    )\n",
    "\n",
    "    # Filter out rows with no total\n",
    "    model_one_df = model_one_df.filter(F_col(\"total\") != 0)\n",
    "\n",
    "    # Calculate percentage of totals for category 1\n",
    "    model_one_df = model_one_df.withF_column(\n",
    "        \"category_1_pct\", F_col(\"category_1\") / F_col(\"total\")\n",
    "    )\n",
    "\n",
    "    # Calculate percentage of totals for category 2\n",
    "    model_one_df = model_one_df.withF_column(\n",
    "        \"category_2_pct\", F_col(\"category_2\") / F_col(\"total\")\n",
    "    )\n",
    "\n",
    "    # Calculate percentage of totals for category 3\n",
    "    model_one_df = model_one_df.withF_column(\n",
    "        \"category_3_pct\", F_col(\"category_3\") / F_col(\"total\")\n",
    "    )\n",
    "\n",
    "    # Write table to Snowflake\n",
    "    model_one_df.write.mode(\"overwrite\").save_as_table(\"data_model_one\")\n",
    "\n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the data_engineering function as a stored procedure in Snowflake\n",
    "procedure = session.sproc.register(\n",
    "    func=data_engineering,\n",
    "    name=\"data_engineering\",\n",
    "    packages=[\"snowflake-snowpark-python\"],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML\",\n",
    "    replace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data engineering task with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL to create the task\n",
    "create_task_sql = \"\"\"\n",
    "CREATE OR REPLACE TASK data_engineering_task\n",
    "WAREHOUSE = fishtalk_ml_warehouse \n",
    "SCHEDULE = \"USING CRON 0 0 * * * UTC\"\n",
    "COMMENT = \"Daily run of data_engineering\"\n",
    "AS\n",
    "CALL data_engineering();\n",
    "\"\"\"\n",
    "\n",
    "# SQL to enable the task\n",
    "enable_task_sql = \"ALTER TASK data_engineering_task RESUME\"\n",
    "\n",
    "# Create the task\n",
    "session.sql(create_task_sql).collect()\n",
    "\n",
    "# Enable the task\n",
    "session.sql(enable_task_sql).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data engineering task with Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the task object\n",
    "data_engineering_task_py = Task(\n",
    "    definition=StoredProcedureCall(procedure),\n",
    "    name=\"data_engineering_task_py\",\n",
    "    warehouse=\"fishtalk_ml_warehouse\",\n",
    "    schedule=Cron(\"0 0 * * *\", \"UTC\"),\n",
    "    comment=\"Daily run of data_engineering\",\n",
    ")\n",
    "\n",
    "# Create the task\n",
    "root = Root(session)\n",
    "tasks = root.databases[\"data\"].schemas[\"ml\"].tasks\n",
    "tasks.create(data_engineering_task_py)\n",
    "\n",
    "# Enable the task\n",
    "task_res = tasks[\"data_engineering_task_py\"]\n",
    "task_res.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
